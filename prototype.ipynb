{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import subprocess\n",
    "import io\n",
    "import shutil\n",
    "import threading\n",
    "from queue import Queue\n",
    "from pathlib import Path\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for parsing and reading chuncks of the .WET data\n",
    "def read_warc_record(reader):\n",
    "    ret = {\"header\": \"\", \"body\": b\"\"}\n",
    "\n",
    "    first_line = reader.readline().decode(\"utf-8\")\n",
    "\n",
    "    if first_line != \"WARC/1.0\\r\\n\":\n",
    "        raise ValueError(f\"warc version expected 'WARC/1.0' found {first_line}\")\n",
    "\n",
    "    warc_header_builder = []\n",
    "    content_length = -1\n",
    "\n",
    "    # Iterate through lines until \\r\\n is reached\n",
    "    for line in iter(reader.readline, b\"\\r\\n\"):\n",
    "        # Decode each line to utf-8 format\n",
    "        line = line.decode(\"utf-8\")\n",
    "\n",
    "        # Break if end of block\n",
    "        if line == \"\\r\\n\":\n",
    "            break\n",
    "        \n",
    "        # If you reach a line that starts with content-length\n",
    "        if line.lower().startswith(\"content-length:\"):\n",
    "            if content_length > 0:\n",
    "                raise ValueError(\"exactly one content-length should be present in a WARC header\")\n",
    "            key, value = line.split(\":\", 1)\n",
    "            str_value = value.strip()\n",
    "            # You save the number next to content length and read the number in the body part with reader.read(content_length)\n",
    "            content_length = int(str_value)\n",
    "\n",
    "        warc_header_builder.append(line)\n",
    "\n",
    "    if content_length == 0:\n",
    "        return {\"header\": \"\".join(warc_header_builder), \"body\": b\"\"}\n",
    "\n",
    "    \n",
    "    body = reader.read(content_length).decode(\"utf-8\")\n",
    "    return {\"header\": \"\".join(warc_header_builder), \"body\": body}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use read_warc_record to iterate through file and write files based on language\n",
    "def classify_files(path):\n",
    "    try:\n",
    "        with open(path, \"rb\") as infile:\n",
    "            buf_in = io.BufferedReader(infile)\n",
    "\n",
    "            for record in iter(lambda: read_warc_record(buf_in), {\"header\": \"\", \"body\": b\"\"}):\n",
    "\n",
    "                input_string = record['header']\n",
    "                # Use regular expression to extract the value after \"Identified-Content-Language:\"\n",
    "                match = re.search(r'WARC-Identified-Content-Language:\\s*(\\w+)', input_string)\n",
    "\n",
    "                if match:\n",
    "                    identified_language = match.group(1)\n",
    "\n",
    "                    with open(f'./clean_data/{identified_language}.txt', 'a') as file:\n",
    "                        file.write(str(record['body']))\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "                # blank.append(record)\n",
    "                buf_in.readline()\n",
    "                buf_in.readline()\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(\"End of file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate lines within the new text files we grouped by languages\n",
    "def remove_duplicates_inplace(file_path):\n",
    "    unique_lines = set()\n",
    "\n",
    "    # Read the file and collect unique lines\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        unique_lines.update(line.strip() for line in lines)\n",
    "\n",
    "    # Write unique lines back to the file\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write('\\n'.join(unique_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_filenames(folder_path):\n",
    "    filenames = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        full_path = os.path.join(folder_path, filename)\n",
    "        if os.path.isfile(full_path):\n",
    "            filenames.append(filename)\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_folder_size(folder_path):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for filename in filenames:\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            total_size += os.path.getsize(file_path)\n",
    "    return total_size\n",
    "\n",
    "def format_size(size):\n",
    "    # Convert bytes to a human-readable format (e.g., KB, MB, GB)\n",
    "    for unit in ['B', 'KB', 'MB', 'GB']:\n",
    "        if size < 1024.0:\n",
    "            return f\"{size:.2f} {unit}\"\n",
    "        size /= 1024.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of file\n"
     ]
    }
   ],
   "source": [
    "filenames = get_filenames('./data/')\n",
    "\n",
    "for i in filenames: \n",
    "    classify_files(f'./data/{i}')\n",
    "    clean_data_dir = get_filenames('./clean_data/')\n",
    "    for filename in clean_data_dir:\n",
    "        remove_duplicates_inplace(f'./clean_data/{filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total size of the folder \"./clean_data/\" is: 528.38 MB\n"
     ]
    }
   ],
   "source": [
    "folder_path = './clean_data/'  # Replace with your folder path\n",
    "folder_size = get_folder_size(folder_path)\n",
    "print(f'The total size of the folder \"{folder_path}\" is: {format_size(folder_size)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = get_filenames('./clean_data/')\n",
    "for filename in filenames:\n",
    "    remove_duplicates_inplace(f'./clean_data/{filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total size of the folder \"./clean_data/\" is: 228.15 MB\n"
     ]
    }
   ],
   "source": [
    "folder_path = './clean_data/'  # Replace with your folder path\n",
    "folder_size = get_folder_size(folder_path)\n",
    "print(f'The total size of the folder \"{folder_path}\" is: {format_size(folder_size)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSAN5400",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
